str(fake.df.critics)
criticResponses <- rbind(criticResponses, fake.df.critics)
fake.df.critics$`Rotten Tomatoes` <- paste0(fakeScores1, "% (33 reviews)")
fake.df.critics$`Metacritic` <- paste0(fakeScores2, " (34 reviews)")
rm(fake.df.critics)
fake.df.critics <- data.frame(fakeReviews)
names(fake.df.critics) <- c("Season")
fake.df.critics$`Rotten Tomatoes` <- paste0(fakeScores1, "% (33 reviews)")
fake.df.critics$`Metacritic` <- paste0(fakeScores2, " (34 reviews)")
View(fake.df.critics)
head(fake.df.critics)
criticResponses <- rbind(criticResponses, fake.df.critics)
seasons$Season <- as.numeric(seasons$Season)
criticResponses$Season <- as.numeric(criticResponses$Season)
str(criticResponses)
str(fake.df.critics)
seasons <- rbind(seasons, fake.df.seasons)
criticResponses <- rbind(criticResponses, fake.df.critics)
seasons <- htmltab(doc=url, which=2)
seasons$Season <- factor(seasons$Season, levels = c("Season 1", "Season 2",
"Season 3", "Season 4", "Season 5", "Season 6", "Season 7","Season 8"), labels=c(1:8))
criticResponses <- rbind(criticResponses, fake.df.critics)
criticResponses <- htmltab(doc=url, which=4)
criticResponses$Season <- as.factor(criticResponses$Season)
str(criticResponses)
seasons <- rbind(seasons, fake.df.seasons)
criticResponses <- rbind(criticResponses, fake.df.critics)
seasons <- htmltab(doc=url, which=2)
rownames(seasons) <- c(1:8)
criticResponses <- htmltab(doc=url, which=4)
seasons$Season <- factor(seasons$Season, levels = c("Season 1", "Season 2",
"Season 3", "Season 4", "Season 5", "Season 6", "Season 7","Season 8"), labels=c(1:8))
seasons$Season <- as.numeric(seasons$Season)
criticResponses$Season <- as.numeric(criticResponses$Season)
View(seasons)
seasons <- rbind(seasons, fake.df.seasons)
criticResponses <- rbind(criticResponses, fake.df.critics)
seasons$Season <- factor(seasons$Season, levels = c(1:100), labels = c(1:100))
criticResponses$Season <- as.factor(criticResponses$Season)
fakeSeasons <- c(9:100))
print(fakeSeasons)
fakeSeasons <- c(9:100)
print(fakeSeasons)
fakeText <- rep("fake", length(fakeSeasons))
fake.df.seasons <- data.frame(fakeSeasons, fakeText, fakeText, fakeText, fakeText, fakeText)
names(fake.df.seasons) <- names(seasons)
fake.df.seasons$Ordered <- as.character(fake.df.seasons$Ordered)
fake.df.seasons$Filming <- as.character(fake.df.seasons$Filming)
fake.df.seasons$`First aired` <- as.character(fake.df.seasons$`First aired`)
fake.df.seasons$`Last aired` <- as.character(fake.df.seasons$`Last aired`)
fake.df.seasons$`Novel(s) adapted` <- as.character(fake.df.seasons$`Novel(s) adapted`)
head(fake.df.seasons)
seasons <- htmltab(doc=url, which=2)
rownames(seasons) <- c(1:8)
seasons <- rbind(seasons, fake.df.seasons)
seasons <- htmltab(doc=url, which=2)
rownames(seasons) <- c(1:8)
seasons$Season <- factor(seasons$Season, levels = c("Season 1", "Season 2",
"Season 3", "Season 4", "Season 5", "Season 6", "Season 7","Season 8"), labels=c(1:8))
seasons$Season <- as.numeric(seasons$Season)
seasons <- rbind(seasons, fake.df.seasons)
seasons$Season <- factor(seasons$Season, levels = c(1:100), labels = c(1:100))
criticResponses <- htmltab(doc=url, which=4)
rownames(criticResponses)   <- c(1:8)
criticResponses$Season <- as.factor(criticResponses$Season)
str(criticResponses)
criticResponses$Season <- as.numeric(criticResponses$Season)
fake.df.critics$Season <- as.numeric(fake.df.critics$Season)
criticResponses <- rbind(criticResponses, fake.df.critics)
seasons$Season <- factor(seasons$Season, levels = c(1:100), labels = c(1:100))
criticResponses$Season <- as.factor(criticResponses$Season)
url <- "https://api.themoviedb.org/3/tv/1399?api_key=<put your key here>"
GoTJson <- jsonlite::fromJSON(url, flatten = TRUE)
movieDBSeasons <- GoTJson$seasons
url <- "https://api.themoviedb.org/3/tv/1399?api_key=<afe2cb33bdd9525087acc1e7e01789bc>"
GoTJson <- jsonlite::fromJSON(url, flatten = TRUE)
url <- "https://api.themoviedb.org/3/tv/1399?api_key=afe2cb33bdd9525087acc1e7e01789bc"
GoTJson <- jsonlite::fromJSON(url, flatten = TRUE)
View(GoTJson)
movieDBSeasons <- GoTJson$seasons
print(movieDBSeasons)
View(movieDBSeasons)
movieDBSeasons[-c(0),]
View(movieDBSeasons)
movieDBSeasons[-c(1),]
View(movieDBSeasons)
movieDBSeasons <-  movieDBSeasons[-c(1),]
key <- "afe2cb33bdd9525087acc1e7e01789bc"
url <- paste0("https://api.themoviedb.org/3/tv/1399/season/1", "?api_key=", key)
GoTJsonSeason1 <- jsonlite::fromJSON(url, flatten = TRUE)
url <- paste0("https://api.themoviedb.org/3/tv/1399/season/2", "?api_key=", key)
GoTJsonSeason2 <- jsonlite::fromJSON(url, flatten = TRUE)
url <- paste0("https://api.themoviedb.org/3/tv/1399/season/3", "?api_key=", key)
GoTJsonSeason3 <- jsonlite::fromJSON(url, flatten = TRUE)
url <- paste0("https://api.themoviedb.org/3/tv/1399/season/4", "?api_key=", key)
GoTJsonSeason4 <- jsonlite::fromJSON(url, flatten = TRUE)
url <- paste0("https://api.themoviedb.org/3/tv/1399/season/5", "?api_key=", key)
GoTJsonSeason5 <- jsonlite::fromJSON(url, flatten = TRUE)
url <- paste0("https://api.themoviedb.org/3/tv/1399/season/6", "?api_key=", key)
GoTJsonSeason6 <- jsonlite::fromJSON(url, flatten = TRUE)
url <- paste0("https://api.themoviedb.org/3/tv/1399/season/7", "?api_key=", key)
GoTJsonSeason7 <- jsonlite::fromJSON(url, flatten = TRUE)
View(movieDBSeasons)
View(GoTJsonSeason6)
movieDBRatings <- c()
movieDBRatings[1] <- mean(GoTJsonSeason1$episodes$vote_average)
movieDBRatings[2] <- mean(GoTJsonSeason2$episodes$vote_average)
movieDBRatings[3] <- mean(GoTJsonSeason3$episodes$vote_average)
movieDBRatings[4] <- mean(GoTJsonSeason4$episodes$vote_average)
movieDBRatings[5] <- mean(GoTJsonSeason5$episodes$vote_average)
movieDBRatings[6] <- mean(GoTJsonSeason6$episodes$vote_average)
movieDBRatings[7] <- mean(GoTJsonSeason7$episodes$vote_average)
movieDBRatings
movieDBRatings <-movieDBRatings*10
movieDBRatings
View(GoTWikipedia)
GoTWikipedia    <- cbind(GoTWikipedia,movieDBRatings)
View(GoTWikipedia)
movieDBRatings <- rbind(89.00)
movieDBRatings
movieDBRatings <- c()
movieDBRatings[1] <- mean(GoTJsonSeason1$episodes$vote_average)
movieDBRatings[2] <- mean(GoTJsonSeason2$episodes$vote_average)
movieDBRatings[3] <- mean(GoTJsonSeason3$episodes$vote_average)
movieDBRatings[4] <- mean(GoTJsonSeason4$episodes$vote_average)
movieDBRatings[5] <- mean(GoTJsonSeason5$episodes$vote_average)
movieDBRatings[6] <- mean(GoTJsonSeason6$episodes$vote_average)
movieDBRatings[7] <- mean(GoTJsonSeason7$episodes$vote_average)
movieDBRatings[8] <- 89.00
movieDBRatings
movieDBRatings <- c()
movieDBRatings[1] <- mean(GoTJsonSeason1$episodes$vote_average)
movieDBRatings[2] <- mean(GoTJsonSeason2$episodes$vote_average)
movieDBRatings[3] <- mean(GoTJsonSeason3$episodes$vote_average)
movieDBRatings[4] <- mean(GoTJsonSeason4$episodes$vote_average)
movieDBRatings[5] <- mean(GoTJsonSeason5$episodes$vote_average)
movieDBRatings[6] <- mean(GoTJsonSeason6$episodes$vote_average)
movieDBRatings[7] <- mean(GoTJsonSeason7$episodes$vote_average)
movieDBRatings[8] <- 8.9
movieDBRatings <-movieDBRatings*10
movieDBRatings
GoTWikipedia    <- cbind(GoTWikipedia,movieDBRatings)
View(GoTWikipedia)
head(GoTWikipedia[, c("RT", "Critic", "movieDBRatings")])
View(movieDBSeasons)
View(GoTWikipedia)
head(GoTWikipedia[, c("Rotten Tomatoes", "Metacritic", "movieDBRatings")])
library(ggplot2)
library(ggthemes)
library(reshape)
data <- data.frame(GoTWikipedia[, c("Season", "RT", "Critic", "movieDBRatings")])
data$Season <- as.numeric(data$Season)
Molten <- melt(data, id.vars = "Season")
ggplot(Molten, aes(x = Season, y = value, colour = variable)) + geom_line() +
scale_x_continuous(breaks=c(1:7)) + ylab("Average review %")
iinstall.packages("reshape")
install.packages("reshape")
library(reshape)
data <- data.frame(GoTWikipedia[, c("Season", "Rotten Tomatoes", "Metacritic", "movieDBRatings")])
data$Season <- as.numeric(data$Season)
Molten <- melt(data, id.vars = "Season")
ggplot(Molten, aes(x = Season, y = value, colour = variable)) + geom_line() +
scale_x_continuous(breaks=c(1:7)) + ylab("Average review %")
rm(list=ls())
install.packages(MASS)
install.packages("MASS")
library(MASS, lib.loc = "C:/Program Files/R/R-4.0.3/library")
install.packages("ISLR")
library(ISLR)
fix(Boston)
names(Boston)
data(Boston)
force(Boston)
lm.fit=lm(medv~lstat)
lm.fit=lm(medv~lstat,data=Boston)
summary(lm.fit)
help(attach)
coef(lm.fit)
confint(lm.fit)
predict(lm.fit,data.frame(lstat=c(5,10,15)),interval= "confidence")
predict(lm.fit,data.frame(lstat=c(5,10,15)),interval= "prediction")
plot(lstat,medv)
detach("package:ISLR", unload = TRUE)
abline(lm.fit)
plot(lstat,medv)
abline(lm.fit)
attach(Boston)
plot(lstat,medv)
abline(lm.fit)
abline (lm.fit ,lwd =3)
abline (lm.fit ,lwd=3,col ="red")
abline (lm.fit ,lwd =3)
plot(lstat ,medv ,col="red")
plot(lstat ,medv ,pch =20)
plot(lstat ,medv ,pch ="+")
plot(1:20,1:20,pch =1:20)
par(mfrow=c(2,2))
plot(lm.fit)
plot(predict (lm.fit), residuals (lm.fit))
plot(predict (lm.fit), rstudent (lm.fit))
plot(hatvalues (lm.fit))
which.max(hatvalues (lm.fit))
library(readxl)
city_day <- read_excel("F:/OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/DMML/Project/Dataset/indian_central_pollution_board/city_day.xlsx")
View(city_day)
fix(city_day)
names(city_day)
data(city_day)
my_fit=lm(AQI~NO2,data=city_day)
attach(city_day)
attach(city_day)
summary(my_city)
summary(my_fit)
coef(my_fit)
confint(my_fit)
par(mfrow=c(2,2))
plot(lm.fit)
plot(hatvalues (lm.fit))
which.max(hatvalues (lm.fit))
par(mfrow=c(2,2))
plot(lm.fit)
confint(my_fit)
predict(my_fit,data.frame(lstat=c(5,10,15)),interval= "confidence")
predict(my_fit,data.frame(lstat=c(5,10,15)),interval= "prediction")
predict(my_fit,data.frame(NO2=c(5,10,15)),interval= "confidence")
predict(my_fit,data.frame(NO2=c(5,10,15)),interval= "prediction")
plot(AQI,NO2)
plot(AQI,NO2)
plot(AQI,NO2)
abline(my_fit)
abline (my_fit ,lwd =3)
abline (my_fit ,lwd=3,col ="red")
plot(lstat ,medv ,col="red")
plot(AQI,NO2 ,col="red")
plot(AQI,NO2 ,pch =20)
plot(1:20,1:20,pch =1:20)
par(mfrow=c(2,2))
plot(my_fit)
plot(hatvalues (my_fit))
which.max(hatvalues (my_fit))
lm.fit=lm(medv∼lstat+age ,data=Boston )
summary (lm.fit)
lm.fit=lm(medv∼.,data=Boston)
summary (lm.fit)
library (car)
install.packages("car")
library (car)
vif(lm.fit)
vif(lm.fit)
library(readxl)
final <- read_excel("F:/OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/Statistics for Data analysis/Assignments/Datasets/INTIAL/ALCOHOL/combinecsv/final.xlsx")
View(final)
fix(final)
names(final)
data(final)
lm.final=lm(medv~lstat,data=final)
attach(final)
summary(lm.fit)
coef(lm.final)
confint(lm.final)
predict(lm.final,data.frame(lstat=c(5,10,15)),interval= "confidence")
predict(lm.final,data.frame(lstat=c(5,10,15)),interval= "prediction")
library(readxl)
alcohol_abstainers_reduction_column_name_chnage <- read_excel("F:/OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/Statistics for Data analysis/Assignments/Datasets/INTIAL/ALCOHOL/combinecsv/alcohol_abstainers_reduction - column name chnage.xlsx")
View(alcohol_abstainers_reduction_column_name_chnage)
fix(alcohol_abstainers_reduction - column name chnage)
names(alcohol_abstainers_reduction - column name chnage)
data(alcohol_abstainers_reduction - column name chnage)
lm.fit=lm(consumption data=alcohol_abstainers_reduction - column name chnage)
attach(alcohol_abstainers_reduction - column name chnage)
summary(lm.fit)
coef(lm.fit)
confint(lm.fit)
predict(lm.fit,data.frame(lstat=c(5,10,15)),interval= "confidence")
predict(lm.fit,data.frame(lstat=c(5,10,15)),interval= "prediction")
fix(alcohol_abstainers_reduction - column name chnage)
names(alcohol_abstainers_reduction - column name chnage)
data(alcohol_abstainers_reduction - column name chnage)
lm.fit=lm(consumption~ Beer+Wine+Spirit+15-years old+`Unemployment Rate`+leagally defined+national alcohol policy+`Advertising restrictions` data=alcohol_abstainers_reduction - column name chnage)
attach(alcohol_abstainers_reduction - column name chnage)
summary(lm.fit)
coef(lm.fit)
confint(lm.fit)
predict(lm.fit,data.frame(lstat=c(5,10,15)),interval= "confidence")
predict(lm.fit,data.frame(lstat=c(5,10,15)),interval= "prediction")
fix(alcohol_abstainers_reduction - column name chnage)
names(alcohol_abstainers_reduction - column name chnage)
data(alcohol_abstainers_reduction - column name chnage)
lm.fit=lm(consumption~ Beer+Wine+Spirit+15-years old+`Unemployment Rate`+leagally defined+national alcohol policy+`Advertising restrictions` data=alcohol_abstainers_reduction - column name chnage)
attach(alcohol_abstainers_reduction - column name chnage)
summary(lm.fit)
library(readxl)
namechange <- read_excel("F:/OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/Statistics for Data analysis/Assignments/Datasets/INTIAL/ALCOHOL/combinecsv/namechange.xlsx")
View(namechange)
fix(namechange)
names(namechange)
data(namechange)
View(namechange)
data(namechange)
library(MASS)
library(ISLR)
data(namechange)
fix(namechange)
names(namechange)
data(namechange)
fix(namechange)
names(namechange)
data(namechange)
install.packages("MASS")
install.packages("ISLR")
install.packages("MASS")
install.packages("ISLR")
lm.fit=lm(medv~lstat,data=namechange)
attach(namechange)
summary(lm.fit)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+15-years old+`Unemployment Rate`+`legally defined`+`national alcohol policy`+`Advertising restrictions...24`,data=namechange)
attach(namechange)
summary(lm.fit)
lm.fit=lm(consumption ~ 'Beer'+'Wine'+'Spirits+15-years old'+`Unemployment Rate`+`legally defined`+`national alcohol policy`+`Advertising restrictions...24`,data=namechange)
attach(namechange)
summary(lm.fit)
lm.fit=lm(consumption ~ Beer +Wine+Spirits+15-years old +Unemployment Rate+legally defined+national alcohol policy+Advertising restrictions,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+15-years old +Unemployment Rate+legally defined+national alcohol policy+Advertising restrictions,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+Unemployment Rate+legally defined+national alcohol policy+Advertising restrictions,data=namechange)
lm.fit=lm(medv~lstat,data=Boston)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+Unemployment Rate+,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+Unemployment Rate,data=namechange)
lm.fit=lm(consumption ~ Beer,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine,data=namechange)
summary(lm.fit)
lm.fit=lm(consumption ~ Beer+Wine+Spirits,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+15-years old,data=namechange)
library(readxl)
namechange <- read_excel("F:/OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/Statistics for Data analysis/Assignments/Datasets/INTIAL/ALCOHOL/combinecsv/namechange.xlsx")
View(namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+years old,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits,data=namechange)
library(readxl)
namechange <- read_excel("F:/OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/Statistics for Data analysis/Assignments/Datasets/INTIAL/ALCOHOL/combinecsv/namechange.xlsx")
View(namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+yearsold,data=namechange)
data(namechange)
fix(namechange)
names(namechange)
data(namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+yearsold,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+years,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+years+Unemployment,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+years+Unemployment+nationalalcoholpolicy+leagallydefined+Advertisingrestrictions,data=namechange)
lm.fit=lm(consumption ~ Beer+Wine+Spirits+years+Unemployment+nationalalcoholpolicy+legallydefined+Advertisingrestrictions,data=namechange)
attach(namechange)
summary(lm.fit)
coef(lm.fit)
confint(lm.fit)
predict(lm.fit,data.frame(lstat=c(5,10,15)),interval= "confidence")
predict(lm.fit,data.frame(lstat=c(5,10,15)),interval= "prediction")
par(mfrow=c(2,2))
plot(lm.fit)
plot(predict (lm.fit), residuals (lm.fit))
plot(predict (lm.fit), rstudent (lm.fit))
plot(hatvalues (lm.fit))
which.max(hatvalues (lm.fit))
par(mfrow=c(2,2))
plot(lm.fit)
plot(predict (lm.fit), residuals (lm.fit))
plot(predict (lm.fit), rstudent (lm.fit))
abline (lm.fit ,lwd=3,col ="red")
plot(hatvalues (lm.fit))
which.max(hatvalues (lm.fit))
plot(consumption ~ Beer,Wine,Spirits,years,Unemployment,nationalalcoholpolicy,legallydefined+Advertisingrestrictions)
par(mfrow=c(2,2))
plot(lm.fit)
plot(predict (lm.fit), residuals (lm.fit))
plot(predict (lm.fit), rstudent (lm.fit))
plot(hatvalues (lm.fit))
which.max(hatvalues (lm.fit))
rm(list=ls())
set.seed()
train=sample(392,196)
library(ISLR)
set.seed(1)
lm.fit=lm(mpg∼horsepower ,data=Auto ,subset=train)
attach(Auto)
mean((mpg -predict (lm.fit ,Auto))[-train ]^2)
lm.fit2=lm(mpg∼poly(horsepower ,2),data=Auto , subset=train)
mean((mpg -predict (lm.fit2 ,Auto ))[- train]^2)
lm.fit3=lm(mpg∼poly(horsepower ,3),data=Auto , subset=train)
mean((mpg -predict (lm.fit3 ,Auto ))[- train]^2)
set.seed(2)
train=sample (392,196)
lm.fit=lm(mpg∼horsepower ,subset=train)
mean((mpg -predict (lm.fit ,Auto))[-train ]^2)
mean((mpg -predict (lm.fit ,Auto))[-train ]^2)
lm.fit2=lm(mpg∼poly(horsepower ,2),data=Auto , subset=train)
mean((mpg -predict (lm.fit2 ,Auto ))[- train]^2)
lm.fit3=lm(mpg∼poly(horsepower ,3),data=Auto , subset=train)
mean((mpg -predict (lm.fit3 ,Auto ))[- train]^2)
rm(list=ls())
library(ISLR)
set.seed(1)
train=sample(392,196)
lm.fit=lm(mpg∼horsepower ,data=Auto ,subset=train)
attach(Auto)
mean((mpg -predict (lm.fit ,Auto))[-train ]^2)
lm.fit2=lm(mpg∼poly(horsepower ,2),data=Auto , subset=train)
mean((mpg -predict (lm.fit2 ,Auto ))[- train]^2)
lm.fit3=lm(mpg∼poly(horsepower ,3),data=Auto , subset=train)
mean((mpg -predict (lm.fit3 ,Auto ))[- train]^2)
set.seed(2)
train=sample (392,196)
lm.fit=lm(mpg∼horsepower ,subset=train)
mean((mpg -predict (lm.fit ,Auto))[-train ]^2)
lm.fit2=lm(mpg∼poly(horsepower ,2),data=Auto , subset=train)
mean((mpg -predict (lm.fit2 ,Auto ))[- train]^2)
lm.fit3=lm(mpg∼poly(horsepower ,3),data=Auto , subset=train)
mean((mpg -predict (lm.fit3 ,Auto ))[- train]^2)
glm.fit=glm(mpg∼horsepower ,data=Auto)
coef(glm.fit)
glm.fit=glm(mpg∼horsepower ,data=Auto)
coef(glm.fit)
lm.fit=lm(mpg∼horsepower ,data=Auto)
coef(lm.fit)
library(boot)
glm.fit=glm(mpg∼horsepower ,data=Auto)
cv.err=cv.glm(Auto ,glm.fit)
cv.err$delta
cv.error=rep(0,5)
for (i in 1:5){
+ glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)
+ cv.error[i]=cv.glm(Auto ,glm.fit)$delta [1]
+ }
cv.error
cv.error=rep(0,5)
for (i in 1:5){
+ glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto) + cv.error[i]=cv.glm(Auto ,glm.fit)$delta [1]+ }
cv.error
cv.error=rep(0,5)
for (i in 1:5){
glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto) + cv.error[i]=cv.glm(Auto ,glm.fit)$delta [1] }
cv.error
cv.error=rep(0,5)
for (i in 1:5){
glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto) + cv.error[i]=cv.glm(Auto ,glm.fit)$delta [1] }
cv.error
cv.error=rep(0,5)
for (i in 1:5){
+ glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto) + cv.error[i]=cv.glm(Auto ,glm.fit)$delta [1] +}
cv.error
set.seed(17)
cv.error.10=rep(0 ,10)
for (i in 1:10){
+ glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)
+ cv.error .10[i]=cv.glm(Auto ,glm.fit ,K=10) $delta [1]
+ }
cv.error.10
set.seed(17)
cv.error.10=rep(0 ,10)
for (i in 1:10){
+ glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)
+ cv.error.10[i]=cv.glm(Auto ,glm.fit ,K=10) $delta [1]
+ }
cv.error.10
set.seed(17)
cv.error.10=rep(0 ,10)
for (i in 1:10){
glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)
cv.error.10[i]=cv.glm(Auto ,glm.fit ,K=10) $delta [1]
}
cv.error.10
cv.error=rep(0,5)
for (i in 1:5){
glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm(Auto ,glm.fit)$delta [1]
}
cv.error
load("F:/OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/DMML/Project/Dataset/AIRQUALITYDATASET/2/.RData")
View(cv.err)
rm(list=ls())
load("F:/OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/DMML/Project/Dataset/AIRQUALITYDATASET/1/.RData")
colSums(is.na(AQIDATA))
setwd("F://OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/Statistics for Data analysis/Assignments/TABA/Time Series Analysis/Datasets")
France_Con <- read.csv("France_Energy_Consumption.csv", header=T, na.strings=c(""), stringsAsFactors = T)
rm(list=ls())
setwd("F://OneDrive - National College of Ireland/NCI/SEMESTER 1/SUBJECTS/Statistics for Data analysis/Assignments/TABA/Time Series Analysis/Datasets")
France_Con <- read.csv("France_Energy_Consumption.csv", header=T, na.strings=c(""), stringsAsFactors = T)
tsFrance <- ts(France_Con,start = c(2016,1),end=c(2020,10) ,frequency = 12)
nsdiffs(tsFrance)
library(fpp2)
nsdiffs(tsFrance)
ndiffs(tsFrance)
nsdiffs(tsFrance)
autofit<-auto.arima(tsFrance)
qqnorm(autofit$residuals)
qqline(autofit$residuals)
Box.test(autofit$residuals, type = "Ljung-Box")
checkresiduals(autofit)
forecast(autofit,4)
fit <-arima(tsFrance,order = c(2,0,1))
fit
qqnorm(fit$residuals)
qqline(fit$residuals)
Box.test(fit$residuals, type = "Ljung-Box")
checkresiduals(fit)
forecast(fit,4)
plot(forecast(fit,4),Xlab="Month",ylab="Consumption")
summary(fit)
fit
summary(fit)
HWA<-hw(tsFrance,seasonal = "additive")
HWM<-hw(tsFrance,seasonal = "multiplicative")
HWA
